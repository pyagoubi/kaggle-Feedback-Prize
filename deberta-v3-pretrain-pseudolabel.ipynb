{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"SAVE_PATH = './'\nTRAIN_PATH = '../input/pseudolabels-deberta-base/pseudolabels.csv'\nTARGET_COLS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']","metadata":{"execution":{"iopub.status.busy":"2022-10-19T09:44:11.672627Z","iopub.execute_input":"2022-10-19T09:44:11.673394Z","iopub.status.idle":"2022-10-19T09:44:11.695941Z","shell.execute_reply.started":"2022-10-19T09:44:11.673303Z","shell.execute_reply":"2022-10-19T09:44:11.695037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install iterative-stratification\n!pip install sentencepiece\n!pip install transformers==4.21.2\n#!pip install iterative-stratification --no-index --find-links=file:../input/iterstratification/iterstrat\n\nimport warnings\nimport sentencepiece\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000) \nfrom tqdm import tqdm\nimport transformers\nimport torch\nimport torch.nn as nn\nfrom torch import autocast\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, BertModel, BertTokenizer\n\nprint('Transformer Version: ', transformers.__version__)","metadata":{"id":"KxsDW5bmDL3v","execution":{"iopub.status.busy":"2022-10-19T09:44:11.700080Z","iopub.execute_input":"2022-10-19T09:44:11.700974Z","iopub.status.idle":"2022-10-19T09:44:55.963337Z","shell.execute_reply.started":"2022-10-19T09:44:11.700938Z","shell.execute_reply":"2022-10-19T09:44:55.962212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class cfg:\n    model= 'microsoft/deberta-v3-base'\n    gradient_checkpointing=True\n    epochs=10\n    eps=1e-6\n    num_workers=4\n    batch_size=2\n    weight_decay=0.01\n    target_cols=TARGET_COLS\n    seed=42\n    train=True\n    #scheduler='cosine' # ['linear', 'cosine']\n    #batch_scheduler=True\n    #num_cycles=0.5\n    num_warmup_steps=0\n    epochs=4\n    encoder_lr=2e-5\n    decoder_lr=2e-5\n    min_lr=1e-6\n    eps=1e-6\n    betas=(0.9, 0.999)\n    print_freq = 100\n    #max_len=512\n\n\n\n\n\ndef import_data(tr =TRAIN_PATH):\n  df_train = pd.read_csv(tr)\n  return df_train\n\ndef replace_nl(df_train, df_test):\n  df_train['full_text'] = df_train['full_text'].str.replace(pat=r'[\\n\\r\\t\\\\]', repl= r'', regex=True)\n  df_test['full_text'] = df_test['full_text'].str.replace(pat=r'[\\n\\r\\t\\\\]', repl=r'', regex=True)\n  return df_train, df_test\n\ndef train_test_split(df, frac=0.2):\n    \n    # get random sample \n    test = df.sample(frac=frac, axis=0)\n\n    # get everything but the test sample\n    train = df.drop(index=test.index)\n\n    return train, test\n\ndef load_prepare():\n  df_train = import_data()\n  df_train, df_val = train_test_split(df_train, frac=0.2)\n  return df_train, df_val\n\n","metadata":{"id":"JpNOcDU65l2q","execution":{"iopub.status.busy":"2022-10-19T09:44:55.965231Z","iopub.execute_input":"2022-10-19T09:44:55.966186Z","iopub.status.idle":"2022-10-19T09:44:55.983598Z","shell.execute_reply.started":"2022-10-19T09:44:55.966143Z","shell.execute_reply":"2022-10-19T09:44:55.979398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_val = load_prepare()","metadata":{"id":"oi4-ULuW8-7B","outputId":"556065df-4d40-420c-8cdd-6b804c5282cc","execution":{"iopub.status.busy":"2022-10-19T09:44:55.989038Z","iopub.execute_input":"2022-10-19T09:44:55.989991Z","iopub.status.idle":"2022-10-19T09:44:56.095801Z","shell.execute_reply.started":"2022-10-19T09:44:55.989866Z","shell.execute_reply":"2022-10-19T09:44:56.094841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2022-10-19T10:11:02.817142Z","iopub.execute_input":"2022-10-19T10:11:02.818126Z","iopub.status.idle":"2022-10-19T10:11:02.845643Z","shell.execute_reply.started":"2022-10-19T10:11:02.818076Z","shell.execute_reply":"2022-10-19T10:11:02.844687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(cfg.model)\ntokenizer.save_pretrained(SAVE_PATH+'tokenizer/')\ncfg.tokenizer = tokenizer\n\n\n\n#Dataset Deberta Base\nclass Dataset_Db(torch.utils.data.Dataset):\n\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.labels = df[cfg.target_cols].values\n        self.texts = df[[\"full_text\"]].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        batch_texts = cfg.tokenizer(self.texts[idx][0], \n                                padding='max_length', \n                                max_length = 1450, \n                                truncation=True, \n                                return_tensors=None, \n                                add_special_tokens=True,\n                                pad_to_max_length=True                     \n                                )\n        \n        for k, v in batch_texts.items():\n          batch_texts[k] = torch.tensor(v, dtype=torch.long)\n\n        batch_y = torch.tensor(self.labels[idx], dtype=torch.float)\n        return batch_texts, batch_y\n\n\n#Model Deberta Base\n\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\n\nclass DBB(nn.Module):\n  def __init__(self, cfg):\n    super().__init__()\n    self.cfg = cfg\n    self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n    self.config.hidden_dropout = 0.\n    self.config.hidden_dropout_prob = 0.\n    self.config.attention_dropout = 0.\n    self.config.attention_probs_dropout_prob = 0.\n    self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n    self.pool = MeanPooling()\n    self.out = nn.Linear(self.config.hidden_size, 6)\n    self._init_weights(self.out)\n\n  def _init_weights(self, module):\n      if isinstance(module, nn.Linear):\n          module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n          if module.bias is not None:\n              module.bias.data.zero_()\n      elif isinstance(module, nn.Embedding):\n          module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n          if module.padding_idx is not None:\n              module.weight.data[module.padding_idx].zero_()\n      elif isinstance(module, nn.LayerNorm):\n          module.bias.data.zero_()\n          module.weight.data.fill_(1.0)\n\n  def forward(self, inputs):\n      outputs = self.model(**inputs)\n      last_hidden_states = outputs[0]\n      pooled_output = self.pool(last_hidden_states, inputs['attention_mask'])\n      final_out = self.out(pooled_output)\n      return final_out\n    \n# ====================================================\n#####Loss\n#====================================================\nclass RMSELoss(nn.Module):\n    def __init__(self, reduction='mean', eps=1e-9):\n        super().__init__()\n        self.mse = nn.MSELoss(reduction='none')\n        self.reduction = reduction\n        self.eps = eps\n\n    def forward(self, y_pred, y_true):\n        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n        if self.reduction == 'none':\n            loss = loss\n        elif self.reduction == 'sum':\n            loss = loss.sum()\n        elif self.reduction == 'mean':\n            loss = loss.mean()\n        return loss\n\n\ndef get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n          'lr': encoder_lr, 'weight_decay': weight_decay},\n        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n          'lr': encoder_lr, 'weight_decay': 0.0},\n        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n          'lr': decoder_lr, 'weight_decay': 0.0}\n    ]\n    return optimizer_parameters\n\ndef collate(inputs):\n    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n    for k, v in inputs.items():\n        inputs[k] = inputs[k][:,:mask_len]\n    return inputs\n\n","metadata":{"id":"vqhigdnNAGYq","execution":{"iopub.status.busy":"2022-10-19T08:49:39.008201Z","iopub.execute_input":"2022-10-19T08:49:39.008586Z","iopub.status.idle":"2022-10-19T08:49:46.061539Z","shell.execute_reply.started":"2022-10-19T08:49:39.008550Z","shell.execute_reply":"2022-10-19T08:49:46.060579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{"id":"LU84H01xiSZc"}},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler()\n\n\n\noof_df = pd.DataFrame()\n\n\nvalid_labels = df_val[cfg.target_cols].values\n\ntrain_dataset = Dataset_Db(cfg, df_train)\nvalid_dataset = Dataset_Db(cfg, df_val)\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=cfg.batch_size,\n                          shuffle=True,\n                          num_workers=cfg.num_workers, \n                          pin_memory=True#, \n                          #drop_last=True\n                          )\nvalid_loader = DataLoader(valid_dataset,\n                          batch_size=cfg.batch_size * 2,\n                          shuffle=False,\n                          num_workers=cfg.num_workers, pin_memory=True, drop_last=False)\n\nmodel = DBB(cfg)\n#torch.save(model.config, OUTPUT_DIR+'config.pth')\nmodel.to(device)\n\noptimizer_parameters = get_optimizer_params(model,\n                                            encoder_lr=cfg.encoder_lr, \n                                            decoder_lr=cfg.decoder_lr,\n                                            weight_decay=cfg.weight_decay)\n\noptimizer = AdamW(optimizer_parameters, lr=cfg.encoder_lr, eps=cfg.eps, betas=cfg.betas)\n\ncriterion = RMSELoss() #RMSELoss(reduction=\"mean\")\n\n#best_score = np.inf\n\n\nfor epoch in range(cfg.epochs):\n\n    model.train()\n    scaler = torch.cuda.amp.GradScaler(enabled=True)\n\n    losses = []\n    counter = 0\n\n    #train\n    for step, (inputs, labels) in enumerate(train_loader):\n        inputs = collate(inputs)\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        #with torch.cuda.amp.autocast(enabled=True):\n        y_preds = model(inputs)\n        loss = criterion(y_preds, labels)\n\n        losses.append(loss*batch_size)\n        counter += batch_size\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n        total = sum(losses)/counter\n\n        if step % cfg.print_freq == 0 or step == (len(train_loader)-1):\n            print(f'Epoch: [{epoch}][{step}/{len(train_loader)}]  \\n',\n                f'Loss: {total}')\n\n\n\n  #validation\n\n    val_losses = []\n    ep = []\n    ep_losses = []\n    val_counter = 0\n    preds = []\n    model.eval()\n\n    for step, (inputs, labels) in enumerate(valid_loader):\n        inputs = collate(inputs)\n\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with torch.no_grad():\n            val_y_preds = model(inputs)\n            val_loss = criterion(val_y_preds, labels)\n\n        val_losses.append(val_loss*batch_size)\n        val_counter += batch_size\n\n        total_val = sum(val_losses)/val_counter\n        preds.append(val_y_preds.to('cpu').numpy())\n        \n    \n    \n    total_val_loss = sum(val_losses)/val_counter\n    ep.append(epoch)\n    ep_losses.append(total_val_loss)\n\n\n\npredictions = np.concatenate(preds)\ntotal_val_loss = sum(val_losses)/val_counter\n\n\nprint(f'***************EVAL: Loss: {total_val_loss}')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(ep, ep_losses)\n\n\ntorch.save({'model': model.state_dict(),\n                  'predictions': predictions},\n                  SAVE_PATH+f\"{cfg.model.replace('/', '-')}_pretrain_PL.pth\")\n","metadata":{"id":"3IGJPW0jF1m4","outputId":"fa2a0771-7593-428e-dfcc-8fdedfdc2a47","trusted":true},"execution_count":null,"outputs":[]}]}